name: nest-tiny-qat
training_type: quantization
model: nest-tiny
dataset: cifar-10
ngpus: 1
train_batch_size: 192
test_batch_size: 100
num_workers: 8
nepochs: 100
optimizer: AdamW
warmup_scheduler: LinearLR
train_scheduler: CosineAnnealingLR
warmup_epochs: 5
warmup_lr: 2.5e-05
lr: 0.0005
lr_min: 0.00035
lr_restart: 300
weight_decay: 0.05
loss: ce-loss
save_every: 50
resume: false
verbose: false
run_type: individual
sweep_parameters: []
