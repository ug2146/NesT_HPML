name: nest-tiny-qat
training_type: quantization
model: nest-tiny
dataset: cifar-10

ngpus: 1
train_batch_size: 192
test_batch_size: 100
num_workers: 8
nepochs: 100
optimizer: AdamW
warmup_scheduler: LinearLR
train_scheduler: CosineAnnealingLR
warmup_epochs: 5
warmup_lr: 2.5e-5
lr: 2.0e-3
lr_min: 5.0e-4
lr_restart: 100
weight_decay: 0.05
loss: ce-loss

save_every: 50

resume: False
verbose: False

run_type: 'individual' # 'individual/sweep'
sweep_parameters: []
#   preset:
#   - 'ReRamESPreset'
#   - 'ReRamSBPreset'
#   - 'EcRamPreset'
#   - 'PCMPreset'
#   - 'ReRamES2Preset' 
#   - 'EcRamMO2Preset'
#   - 'ReRamSB4Preset'
#   - 'EcRam4Preset'
#   - 'TikiTakaReRamESPreset'
#   - 'TikiTakaEcRamPreset'
#   - 'MixedPrecisionReRamESPreset'
#   - 'MixedPrecisionEcRamMOPreset'
#   - 'MixedPrecisionPCMPreset'
#   - 'CapacitorPresetDevice'
#   - 'EcRamMOPresetDevice'
#   - 'GokmenVlasovPresetDevice'
#   - 'PCMPresetDevice'
#   - 'ReRamArrayHfO2PresetDevice'
